{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac47b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/n/nrushad/.conda/envs/BuildingsBenchEnv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from buildings_bench import load_torch_dataset\n",
    "from buildings_bench.models import model_factory\n",
    "\n",
    "import tomli\n",
    "from pathlib import Path\n",
    "from os import environ\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e715fda-612f-45ef-aa4e-8a953b5a2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Handler ===\n",
    "class DataHandler:\n",
    "    def __init__(self, batch_size=32):\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def load_dataset(self, dataset_name, scaler_transform):\n",
    "        from buildings_bench import load_torch_dataset\n",
    "        return list(load_torch_dataset(\n",
    "            dataset_name,\n",
    "            apply_scaler_transform=scaler_transform,\n",
    "            scaler_transform_path=Path(environ[\"TRANSFORM_PATH\"])\n",
    "        ))\n",
    "\n",
    "    def create_dataloader(self, dataset):\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef5e153-8f21-4e12-aee9-6994d0308f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesSinusoidalPeriodicEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim: int):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, embedding_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"`x` is expected to be [batch_size, seqlen, 1] in [-1, +1] range.\"\"\"\n",
    "        x = torch.cat([torch.sin(torch.pi * x), torch.cos(torch.pi * x)], dim=2)\n",
    "        return self.linear(x)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    DEFAULT_CONTEXT_LEN = 168\n",
    "    DEFAULT_PRED_LEN = 24\n",
    "\n",
    "    def __init__(self, activation):\n",
    "        super().__init__()\n",
    "        self.context_len = self.DEFAULT_CONTEXT_LEN\n",
    "        self.pred_len = self.DEFAULT_PRED_LEN\n",
    "        self.activation = self._get_activation(activation)\n",
    "        self.embeddings = self._create_embeddings()\n",
    "\n",
    "    def _create_embeddings(self):\n",
    "        return nn.ModuleDict({\n",
    "            'power': nn.Linear(1, 64),\n",
    "            'building': nn.Embedding(2, 32),\n",
    "            'lat': nn.Linear(1, 32),\n",
    "            'lon': nn.Linear(1, 32), \n",
    "            'day_of_year': TimeSeriesSinusoidalPeriodicEmbedding(32),\n",
    "            'day_of_week': TimeSeriesSinusoidalPeriodicEmbedding(32),\n",
    "            'hour_of_day': TimeSeriesSinusoidalPeriodicEmbedding(32)\n",
    "        })\n",
    "\n",
    "    def _get_activation(self, name):\n",
    "        return {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"gelu\": nn.GELU(),\n",
    "            \"leaky_relu\": nn.LeakyReLU()\n",
    "        }.get(name.lower(), nn.ReLU())\n",
    "\n",
    "    def _data_pre_process(self, x):\n",
    "        lat = self.embeddings['lat'](x['latitude'])\n",
    "        lon = self.embeddings['lon'](x['longitude'])\n",
    "        btype = self.embeddings['building'](x['building_type'].squeeze(-1))\n",
    "        load = self.embeddings['power'](x['load'])\n",
    "        day_of_year = self.embeddings['day_of_year'](x['day_of_year'])            \n",
    "        day_of_week = self.embeddings['day_of_week'](x['day_of_week'])            \n",
    "        hour_of_day = self.embeddings['hour_of_day'](x['hour_of_day']) \n",
    "        return torch.cat([lat, lon, btype, day_of_year, day_of_week, hour_of_day, load], dim=2)\n",
    "\n",
    "\n",
    "class NN(Model):\n",
    "    def __init__(self, activation):\n",
    "        super().__init__(activation)\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        input_dim = self.context_len * 256\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(input_dim, 512), self.activation,\n",
    "            nn.Linear(512, 256), self.activation,\n",
    "            nn.Linear(256, 128), self.activation,\n",
    "            nn.Linear(128, self.pred_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ts_embed = self._data_pre_process(x)\n",
    "        x_flat = ts_embed[:, :self.context_len, :].reshape(x['load'].shape[0], -1)\n",
    "        return self.model(x_flat).unsqueeze(-1)\n",
    "\n",
    "class RNN(Model):\n",
    "    def __init__(self, activation=\"relu\"):\n",
    "        super().__init__(activation)\n",
    "        self.rnn1, self.rnn2, self.output_layer = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        rnn1 = nn.RNN(256, 128, batch_first=True)\n",
    "        rnn2 = nn.RNN(128, 128, batch_first=True)\n",
    "        output_layer = nn.Linear(128, self.pred_len)\n",
    "        return rnn1, rnn2, output_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        ts_embed = self._data_pre_process(x)\n",
    "        out1, _ = self.rnn1(ts_embed)\n",
    "        out2, _ = self.rnn2(out1)\n",
    "        last_hidden = self.activation(out2[:, -1, :])\n",
    "        return self.output_layer(last_hidden).unsqueeze(-1)\n",
    "\n",
    "class LSTM(Model):\n",
    "    def __init__(self, activation=\"relu\"):\n",
    "        super().__init__(activation)\n",
    "        self.lstm1, self.lstm2, self.output_layer = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        lstm1 = nn.LSTM(256, 128, batch_first=True)\n",
    "        lstm2 = nn.LSTM(128, 128, batch_first=True)\n",
    "        output_layer = nn.Linear(128, self.pred_len)\n",
    "        return lstm1, lstm2, output_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        ts_embed = self._data_pre_process(x)\n",
    "        out1, _ = self.lstm1(ts_embed)\n",
    "        out2, _ = self.lstm2(out1)\n",
    "        last_hidden = self.activation(out2[:, -1, :])\n",
    "        return self.output_layer(last_hidden).unsqueeze(-1)\n",
    "\n",
    "class GRU(Model):\n",
    "    def __init__(self, activation=\"relu\"):\n",
    "        super().__init__(activation)\n",
    "        self.gru1, self.gru2, self.output_layer = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        gru1 = nn.GRU(256, 128, batch_first=True)\n",
    "        gru2 = nn.GRU(128, 128, batch_first=True)\n",
    "        output_layer = nn.Linear(128, self.pred_len)\n",
    "        return gru1, gru2, output_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        ts_embed = self._data_pre_process(x)\n",
    "        out1, _ = self.gru1(ts_embed)\n",
    "        out2, _ = self.gru2(out1)\n",
    "        last_hidden = self.activation(out2[:, -1, :])\n",
    "        return self.output_layer(last_hidden).unsqueeze(-1)\n",
    "\n",
    "# class Transformer(Model):\n",
    "#     def __init__(self, model_name, activation=\"relu\"):\n",
    "#         super().__init__(activation)\n",
    "\n",
    "#         # Set config and checkpoint paths\n",
    "#         ckpt_map = {\n",
    "#             \"TransformerWithGaussian-S\": \"Transformer_Gaussian_S.pt\",\n",
    "#             \"TransformerWithGaussian-M\": \"Transformer_Gaussian_M.pt\",\n",
    "#             \"TransformerWithGaussian-L\": \"Transformer_Gaussian_L.pt\"\n",
    "#         }\n",
    "#         environ[\"CONFIG_PATH\"] = f\"{environ['REPO_PATH']}/buildings_bench/configs/{model_name}.toml\"\n",
    "#         environ[\"CHECKPOINT_PATH\"] = f\"{environ['PATH']}/checkpoints/{ckpt_map[model_name]}\"\n",
    "\n",
    "#         # Load model and prediction function\n",
    "#         with open(environ[\"CONFIG_PATH\"], \"rb\") as f:\n",
    "#             tomli_args = tomli.load(f)\n",
    "#         model_args = tomli_args['model']\n",
    "\n",
    "#         raw_model, _, predict_fn = model_factory(model_name, model_args)\n",
    "#         self.transformer_model = raw_model.load_from_checkpoint(Path(environ[\"CHECKPOINT_PATH\"]))\n",
    "#         self.predict_fn = predict_fn\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.predict_fn(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3099190-8a3c-4527-b467-8aec1afb8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model_name, device, scaler_transform, activation='relu', optimizer_name='adam', lr=1e-3):\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        self.scaler_transform = scaler_transform\n",
    "        self.activation = activation\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.lr = lr\n",
    "\n",
    "        self.model = self._load_model()\n",
    "        self.optimizer = self._get_optimizer()\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.handler = DataHandler(batch_size=32)\n",
    "\n",
    "        # Only initialize optimizer if the model has trainable parameters\n",
    "        # self.optimizer = (\n",
    "        #     self._get_optimizer() if any(p.requires_grad for p in self.model.parameters()) else None\n",
    "        # )\n",
    "\n",
    "    def _load_model(self):\n",
    "        model_map = {\n",
    "            'NN': NN,\n",
    "            'RNN': RNN,\n",
    "            'LSTM': LSTM,\n",
    "            'GRU': GRU\n",
    "        }\n",
    "        if self.model_name in model_map:\n",
    "            return model_map[self.model_name](activation=self.activation).to(self.device)\n",
    "\n",
    "        # Transformer model path setup and instantiation\n",
    "        # return Transformer(model_name=self.model_name, activation=self.activation).to(self.device)\n",
    "\n",
    "    def _get_optimizer(self):\n",
    "        opt_map = {\n",
    "            'adam': torch.optim.Adam,\n",
    "            'sgd': torch.optim.SGD,\n",
    "            'adamw': torch.optim.AdamW\n",
    "        }\n",
    "        optimizer_cls = opt_map.get(self.optimizer_name.lower(), torch.optim.Adam)\n",
    "        return optimizer_cls(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def train(self, train_buildings, epochs=5):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0.0\n",
    "            for building_id, building_dataset in train_buildings:\n",
    "                dataloader = self.handler.create_dataloader(building_dataset)\n",
    "                for batch in dataloader:\n",
    "                    for key, value in batch.items():\n",
    "                        batch[key] = value.to(self.device)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    predictions = self.model(batch)\n",
    "                    targets = batch['load'][:, self.model.context_len:, 0]\n",
    "                    loss = self.loss_fn(predictions[:, :, 0], targets)\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    total_loss += loss.item()\n",
    "            print(f\"[{self.model_name}] Epoch {epoch + 1}: Loss = {total_loss:.4f}\")\n",
    "        self.model.eval()\n",
    "        return self.model\n",
    "\n",
    "    def evaluate(self, test_buildings):\n",
    "        self.model.eval()\n",
    "        results = {}\n",
    "        mae_total = 0.0\n",
    "        rmse_total = 0.0\n",
    "        r2_total = 0.0\n",
    "        count = 0\n",
    "        for building_id, building_dataset in test_buildings:\n",
    "            inverse_transform = building_dataset.datasets[0].load_transform.undo_transform\n",
    "            dataloader = self.handler.create_dataloader(building_dataset)\n",
    "            target_list = []\n",
    "            prediction_list = []\n",
    "            with torch.no_grad():\n",
    "                for batch in dataloader:\n",
    "                    for key, value in batch.items():\n",
    "                        batch[key] = value.to(self.device)\n",
    "                    predictions = self.model(batch)\n",
    "                    targets = batch['load'][:, self.model.context_len:]\n",
    "                    targets = inverse_transform(targets)\n",
    "                    predictions = inverse_transform(predictions)\n",
    "                    prediction_list.append(predictions.detach().cpu())\n",
    "                    target_list.append(targets.detach().cpu())\n",
    "            predictions_all = torch.cat(prediction_list)\n",
    "            targets_all = torch.cat(target_list)\n",
    "            mae = torch.abs(predictions_all - targets_all).mean().item()\n",
    "            rmse = torch.sqrt(((predictions_all - targets_all) ** 2).mean()).item()\n",
    "            r2 = 1 - (((predictions_all - targets_all) ** 2).sum() / ((targets_all - targets_all.mean()) ** 2).sum()).item()\n",
    "            mae_total += mae\n",
    "            rmse_total += rmse\n",
    "            r2_total += r2\n",
    "            count += 1\n",
    "            results[building_id] = (predictions_all, targets_all)\n",
    "        return results, mae_total / count, rmse_total / count, r2_total / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2a80a-1232-4e76-88b4-520cc0c48e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training NN ---\n",
      "[NN] Epoch 1: Loss = 481.2123\n",
      "[NN] Epoch 2: Loss = 366.1863\n"
     ]
    }
   ],
   "source": [
    "# === Main Execution ===\n",
    "\n",
    "# TBD: ['buildings-900k-test', 'sceaux', 'borealis', 'ideal', 'bdg-2', 'bdg-2:panther', 'bdg-2:fox', 'bdg-2:rat', 'bdg-2:bear', 'electricity', 'smart', 'lcl']\n",
    "\n",
    "# Configuration dictionary\n",
    "# Options: \n",
    "# dataset_name: ideal, electricity, lcl, sceaux\n",
    "# epochs: 10, 20, 30\n",
    "# activation: relu, tanh, leaky_relu, gelu\n",
    "# optimizer: adam, sgd, adamw\n",
    "\n",
    "config = {\n",
    "    \"PATH\": \"/pscratch/sd/n/nrushad\",\n",
    "    \"dataset_name\": \"ideal\",     \n",
    "    \"scaler_transform\": \"boxcox\",\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 5,\n",
    "    \"activation\": \"gelu\",             \n",
    "    \"optimizer_name\": \"adamw\",        \n",
    "    \"lr\": 1e-3\n",
    "}\n",
    "\n",
    "# Set environment variables\n",
    "environ[\"PATH\"] = config[\"PATH\"]\n",
    "environ[\"REPO_PATH\"] = f\"{config['PATH']}/BuildingsBenchTutorial/BuildingsBench\"\n",
    "environ[\"BUILDINGS_BENCH\"] = f\"{config['PATH']}/Dataset\"\n",
    "environ[\"TRANSFORM_PATH\"] = f\"{config['PATH']}/Dataset/metadata/transforms\"\n",
    "\n",
    "# Set device\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load and split dataset\n",
    "handler = DataHandler(batch_size=config[\"batch_size\"])\n",
    "all_buildings = handler.load_dataset(config[\"dataset_name\"], config[\"scaler_transform\"])\n",
    "train_buildings = all_buildings[:int(0.8 * len(all_buildings))]\n",
    "test_buildings = all_buildings[int(0.8 * len(all_buildings)):] \n",
    "\n",
    "model_names = [\n",
    "    'NN',\n",
    "    'RNN',\n",
    "    'LSTM',\n",
    "    'GRU',\n",
    "    # 'TransformerWithGaussian-S',\n",
    "    # 'TransformerWithGaussian-M',\n",
    "    # 'TransformerWithGaussian-L'\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model_name=model_name,\n",
    "        device=device,\n",
    "        scaler_transform=config[\"scaler_transform\"],\n",
    "        activation=config[\"activation\"],\n",
    "        optimizer_name=config[\"optimizer_name\"],\n",
    "        lr=config[\"lr\"]\n",
    "    )\n",
    "\n",
    "    trainer.train(train_buildings, epochs=config[\"epochs\"])\n",
    "\n",
    "    # Evaluate after training\n",
    "    results, mae, rmse, r2 = trainer.evaluate(test_buildings)\n",
    "\n",
    "    print(f\"[{model_name}] Evaluation Metrics:\")\n",
    "    print(f\"  MAE  = {mae:.4f}\")\n",
    "    print(f\"  RMSE = {rmse:.4f}\")\n",
    "    print(f\"  R²   = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e117a20-85d4-4281-bb54-903ed35475bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pscratch/sd/n/nrushad/BuildingsBenchTutorial/BuildingsBench/buildings_bench/configs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BuildingsBenchKernel",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
