{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac47b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from os import environ\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e715fda-612f-45ef-aa4e-8a953b5a2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Handler ===\n",
    "class DataHandler:\n",
    "    def __init__(self, batch_size=32):\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def load_dataset(self, dataset_name, scaler_transform):\n",
    "        from buildings_bench import load_torch_dataset\n",
    "        return list(load_torch_dataset(\n",
    "            dataset_name,\n",
    "            apply_scaler_transform=scaler_transform,\n",
    "            scaler_transform_path=Path(environ[\"TRANSFORM_PATH\"])\n",
    "        ))\n",
    "\n",
    "    def create_dataloader(self, dataset):\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef5e153-8f21-4e12-aee9-6994d0308f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    DEFAULT_CONTEXT_LEN = 168\n",
    "    DEFAULT_PRED_LEN = 24\n",
    "\n",
    "    def __init__(self, activation):\n",
    "        super().__init__()\n",
    "        self.context_len = self.DEFAULT_CONTEXT_LEN\n",
    "        self.pred_len = self.DEFAULT_PRED_LEN\n",
    "        self.activation = self._get_activation(activation)\n",
    "        self.embeddings = self._create_embeddings()\n",
    "\n",
    "    def _create_embeddings(self):\n",
    "        return nn.ModuleDict({\n",
    "            'power': nn.Linear(1, 64),\n",
    "            'building': nn.Embedding(2, 32),\n",
    "            'lat': nn.Linear(1, 32),\n",
    "            'lon': nn.Linear(1, 32)\n",
    "        })\n",
    "\n",
    "    def _get_activation(self, name):\n",
    "        return {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"gelu\": nn.GELU(),\n",
    "            \"leaky_relu\": nn.LeakyReLU()\n",
    "        }.get(name.lower(), nn.ReLU())\n",
    "\n",
    "    def _data_pre_process(self, x):\n",
    "        lat = self.embeddings['lat'](x['latitude'])\n",
    "        lon = self.embeddings['lon'](x['longitude'])\n",
    "        btype = self.embeddings['building'](x['building_type'].squeeze(-1))\n",
    "        load = self.embeddings['power'](x['load'])\n",
    "        return torch.cat([lat, lon, btype, load], dim=2)\n",
    "\n",
    "class NN(Model):\n",
    "    def __init__(self, activation):\n",
    "        super().__init__(activation)\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        input_dim = self.context_len * 160\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(input_dim, 512), self.activation,\n",
    "            nn.Linear(512, 256), self.activation,\n",
    "            nn.Linear(256, 128), self.activation,\n",
    "            nn.Linear(128, self.pred_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ts_embed = self._data_pre_process(x)\n",
    "        x_flat = ts_embed[:, :self.context_len, :].reshape(x['load'].shape[0], -1)\n",
    "        return self.model(x_flat).unsqueeze(-1)\n",
    "\n",
    "class RNN(Model):\n",
    "    def __init__(self, activation=\"relu\"):\n",
    "        super().__init__(activation)\n",
    "        self.rnn1, self.rnn2, self.output_layer = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        rnn1 = nn.RNN(160, 128, batch_first=True)\n",
    "        rnn2 = nn.RNN(128, 128, batch_first=True)\n",
    "        output_layer = nn.Linear(128, self.pred_len)\n",
    "        return rnn1, rnn2, output_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        ts_embed = self._data_pre_process(x)\n",
    "        out1, _ = self.rnn1(ts_embed)\n",
    "        out2, _ = self.rnn2(out1)\n",
    "        last_hidden = self.activation(out2[:, -1, :])\n",
    "        return self.output_layer(last_hidden).unsqueeze(-1)\n",
    "\n",
    "class LSTM(Model):\n",
    "    def __init__(self, activation=\"relu\"):\n",
    "        super().__init__(activation)\n",
    "        self.lstm1, self.lstm2, self.output_layer = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        lstm1 = nn.LSTM(160, 128, batch_first=True)\n",
    "        lstm2 = nn.LSTM(128, 128, batch_first=True)\n",
    "        output_layer = nn.Linear(128, self.pred_len)\n",
    "        return lstm1, lstm2, output_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        ts_embed = self._data_pre_process(x)\n",
    "        out1, _ = self.lstm1(ts_embed)\n",
    "        out2, _ = self.lstm2(out1)\n",
    "        last_hidden = self.activation(out2[:, -1, :])\n",
    "        return self.output_layer(last_hidden).unsqueeze(-1)\n",
    "\n",
    "class GRU(Model):\n",
    "    def __init__(self, activation=\"relu\"):\n",
    "        super().__init__(activation)\n",
    "        self.gru1, self.gru2, self.output_layer = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        gru1 = nn.GRU(160, 128, batch_first=True)\n",
    "        gru2 = nn.GRU(128, 128, batch_first=True)\n",
    "        output_layer = nn.Linear(128, self.pred_len)\n",
    "        return gru1, gru2, output_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        ts_embed = self._data_pre_process(x)\n",
    "        out1, _ = self.gru1(ts_embed)\n",
    "        out2, _ = self.gru2(out1)\n",
    "        last_hidden = self.activation(out2[:, -1, :])\n",
    "        return self.output_layer(last_hidden).unsqueeze(-1)\n",
    "\n",
    "class Transformer(Model):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "\n",
    "        if MODEL == \"TransformerWithGaussian-L\":\n",
    "            environ[\"CHECKPOINT_PATH\"] = f'{PATH}/checkpoints/Transformer_Gaussian_L.pt'\n",
    "        environ[\"CONFIG_PATH\"] = f'{PATH}/configs/{MODEL}.toml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3099190-8a3c-4527-b467-8aec1afb8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model_name, device, scaler_transform, activation='relu', optimizer_name='adam', lr=1e-3):\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        self.scaler_transform = scaler_transform\n",
    "        self.activation = activation\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.lr = lr\n",
    "        self.model = self._load_model()\n",
    "        self.optimizer = self._get_optimizer()\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.handler = DataHandler(batch_size=32)\n",
    "\n",
    "    def _load_model(self):\n",
    "        model_map = {\n",
    "            'NN': NN,\n",
    "            'RNN': RNN,\n",
    "            'LSTM': LSTM,\n",
    "            'GRU': GRU\n",
    "        }\n",
    "        if self.model_name not in model_map:\n",
    "            raise ValueError(f\"Unsupported model: {self.model_name}\")\n",
    "        return model_map[self.model_name](activation=self.activation).to(self.device)\n",
    "\n",
    "    def _get_optimizer(self):\n",
    "        opt_map = {\n",
    "            'adam': torch.optim.Adam,\n",
    "            'sgd': torch.optim.SGD,\n",
    "            'adamw': torch.optim.AdamW\n",
    "        }\n",
    "        optimizer_cls = opt_map.get(self.optimizer_name.lower(), torch.optim.Adam)\n",
    "        return optimizer_cls(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def train(self, train_buildings, epochs=5):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0.0\n",
    "            for building_id, building_dataset in train_buildings:\n",
    "                dataloader = self.handler.create_dataloader(building_dataset)\n",
    "                for batch in dataloader:\n",
    "                    for key, value in batch.items():\n",
    "                        batch[key] = value.to(self.device)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    predictions = self.model(batch)\n",
    "                    targets = batch['load'][:, self.model.context_len:, 0]\n",
    "                    loss = self.loss_fn(predictions[:, :, 0], targets)\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    total_loss += loss.item()\n",
    "            print(f\"[{self.model_name}] Epoch {epoch + 1}: Loss = {total_loss:.4f}\")\n",
    "        self.model.eval()\n",
    "        return self.model\n",
    "\n",
    "    def evaluate(self, test_buildings):\n",
    "        self.model.eval()\n",
    "        results = {}\n",
    "        mae_total = 0.0\n",
    "        rmse_total = 0.0\n",
    "        r2_total = 0.0\n",
    "        count = 0\n",
    "        for building_id, building_dataset in test_buildings:\n",
    "            inverse_transform = building_dataset.datasets[0].load_transform.undo_transform\n",
    "            dataloader = self.handler.create_dataloader(building_dataset)\n",
    "            target_list = []\n",
    "            prediction_list = []\n",
    "            with torch.no_grad():\n",
    "                for batch in dataloader:\n",
    "                    for key, value in batch.items():\n",
    "                        batch[key] = value.to(self.device)\n",
    "                    predictions = self.model(batch)\n",
    "                    targets = batch['load'][:, self.model.context_len:]\n",
    "                    targets = inverse_transform(targets)\n",
    "                    predictions = inverse_transform(predictions)\n",
    "                    prediction_list.append(predictions.detach().cpu())\n",
    "                    target_list.append(targets.detach().cpu())\n",
    "            predictions_all = torch.cat(prediction_list)\n",
    "            targets_all = torch.cat(target_list)\n",
    "            mae = torch.abs(predictions_all - targets_all).mean().item()\n",
    "            rmse = torch.sqrt(((predictions_all - targets_all) ** 2).mean()).item()\n",
    "            r2 = 1 - (((predictions_all - targets_all) ** 2).sum() / ((targets_all - targets_all.mean()) ** 2).sum()).item()\n",
    "            mae_total += mae\n",
    "            rmse_total += rmse\n",
    "            r2_total += r2\n",
    "            count += 1\n",
    "            results[building_id] = (predictions_all, targets_all)\n",
    "        return results, mae_total / count, rmse_total / count, r2_total / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2a80a-1232-4e76-88b4-520cc0c48e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training NN ---\n",
      "[NN] Epoch 1: Loss = 458.7939\n",
      "[NN] Epoch 2: Loss = 449.5711\n",
      "[NN] Epoch 3: Loss = 333.0180\n",
      "[NN] Epoch 4: Loss = 380.2423\n",
      "[NN] Epoch 5: Loss = 307.8425\n",
      "[NN] Epoch 6: Loss = 324.1859\n",
      "[NN] Epoch 7: Loss = 290.6698\n",
      "[NN] Epoch 8: Loss = 294.9895\n",
      "[NN] Epoch 9: Loss = 318.9454\n",
      "[NN] Epoch 10: Loss = 284.7732\n",
      "[NN] MAE: 0.2334, RMSE: 0.3677, R²: -0.0458\n",
      "\n",
      "--- Training RNN ---\n",
      "[RNN] Epoch 1: Loss = 589.9331\n",
      "[RNN] Epoch 2: Loss = 558.1313\n",
      "[RNN] Epoch 3: Loss = 557.0364\n",
      "[RNN] Epoch 4: Loss = 557.1886\n",
      "[RNN] Epoch 5: Loss = 555.6446\n",
      "[RNN] Epoch 6: Loss = 555.3492\n",
      "[RNN] Epoch 7: Loss = 555.5019\n",
      "[RNN] Epoch 8: Loss = 555.5766\n",
      "[RNN] Epoch 9: Loss = 555.6303\n",
      "[RNN] Epoch 10: Loss = 555.6420\n",
      "[RNN] MAE: 0.2624, RMSE: 0.4359, R²: -0.4159\n",
      "\n",
      "--- Training LSTM ---\n",
      "[LSTM] Epoch 1: Loss = 596.2045\n",
      "[LSTM] Epoch 2: Loss = 553.0597\n",
      "[LSTM] Epoch 3: Loss = 529.9367\n",
      "[LSTM] Epoch 4: Loss = 403.3179\n",
      "[LSTM] Epoch 5: Loss = 340.8698\n",
      "[LSTM] Epoch 6: Loss = 301.4939\n"
     ]
    }
   ],
   "source": [
    "# === Main Execution ===\n",
    "\n",
    "# Configuration dictionary\n",
    "config = {\n",
    "    \"PATH\": \"/pscratch/sd/n/nrushad\",\n",
    "    \"dataset_name\": \"ideal\",\n",
    "    \"scaler_transform\": \"boxcox\",\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 10,\n",
    "    \"activation\": \"gelu\",             # Options: relu, tanh, leaky_relu, gelu\n",
    "    \"optimizer_name\": \"adamw\",        # Options: adam, sgd, adamw\n",
    "    \"lr\": 1e-3\n",
    "}\n",
    "\n",
    "# Set environment variables\n",
    "environ[\"PATH\"] = config[\"PATH\"]\n",
    "environ[\"REPO_PATH\"] = f\"{config['PATH']}/BuildingsBenchTutorial/BuildingsBench/\"\n",
    "environ[\"BUILDINGS_BENCH\"] = f\"{config['PATH']}/Dataset\"\n",
    "environ[\"TRANSFORM_PATH\"] = f\"{config['PATH']}/Dataset/metadata/transforms\"\n",
    "\n",
    "# Set device\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load and split dataset\n",
    "handler = DataHandler(batch_size=config[\"batch_size\"])\n",
    "all_buildings = handler.load_dataset(config[\"dataset_name\"], config[\"scaler_transform\"])\n",
    "train_buildings = all_buildings[:int(0.8 * len(all_buildings))]\n",
    "test_buildings = all_buildings[int(0.8 * len(all_buildings)):]\n",
    "\n",
    "# Train and evaluate all models\n",
    "for model_class in [NN, RNN, LSTM, GRU]:\n",
    "    print(f\"\\n--- Training {model_class.__name__} ---\")\n",
    "    trainer = Trainer(\n",
    "        model_name=model_class.__name__,\n",
    "        device=device,\n",
    "        scaler_transform=config[\"scaler_transform\"],\n",
    "        activation=config[\"activation\"],\n",
    "        optimizer_name=config[\"optimizer_name\"],\n",
    "        lr=config[\"lr\"]\n",
    "    )\n",
    "    trainer.train(train_buildings, epochs=config[\"epochs\"])\n",
    "    _, mae, rmse, r2 = trainer.evaluate(test_buildings)\n",
    "    print(f\"[{model_class.__name__}] MAE: {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6760d0a-417c-4abb-a6f4-9a9fab36d092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BuildingsBenchKernel",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
